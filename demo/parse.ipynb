{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlrd\n",
    "import os\n",
    "import gzip\n",
    "from Bio import pairwise2\n",
    "from Bio.pairwise2 import format_alignment\n",
    "from Bio.Seq import Seq\n",
    "from datetime import datetime\n",
    "from Bio import SeqIO\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xl_workbook = xlrd.open_workbook(\"3_lib_final.xlsx\")\n",
    "sheet_names = xl_workbook.sheet_names()\n",
    "xl_sheet = xl_workbook.sheet_by_name(sheet_names[0])\n",
    "\n",
    "prom_lib = {}\n",
    "ref_bc = []\n",
    "ref_bc_last10 = []\n",
    "ref_p = []\n",
    "\n",
    "bc_dict = {}\n",
    "prom_dict = {}\n",
    "\n",
    "#column3 = barcode (reverse complemented to make 5'to3' sequence), column4 = promoter sequence without ATG+Barcode\n",
    "for rnum in range(1,xl_sheet.nrows):\n",
    "    prom_lib[xl_sheet.cell(rnum,5).value] = xl_sheet.cell(rnum,3).value\n",
    "    ref_bc.append(xl_sheet.cell(rnum,5).value)\n",
    "    ref_bc_last10.append(xl_sheet.cell(rnum,3).value[-10:])\n",
    "    ref_p.append(xl_sheet.cell(rnum,3).value)\n",
    "    ref_dict = dict(zip(ref_bc_last10, ref_bc))\n",
    "    \n",
    "DNAfilepaths = []\n",
    "RNAfilepaths = []\n",
    "fp = \"merged\"\n",
    "\n",
    "for subdir, dirs, files in os.walk(fp):\n",
    "    for file in files:\n",
    "        if \"fastq\" in file and \"gz\" in file:\n",
    "            a = subdir.split(\"/\")[-1] + \"/\"\n",
    "            b = file\n",
    "            path = os.path.join(a,b) \n",
    "            if \"D\" in path:\n",
    "                DNAfilepaths.append(path)\n",
    "            elif \"-\" in path:\n",
    "                RNAfilepaths.append(path)\n",
    "            else:\n",
    "                raise(\"errrrrrrrr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_err(phred_arr):\n",
    "    E = 0.0\n",
    "    for q in phred_arr:\n",
    "        E += math.pow(10,(-q/10))\n",
    "    return E   \n",
    "\n",
    "def tabulate(key, counts):\n",
    "    # add 1 to count for this key, or add it to the dictionary    \n",
    "    if key in counts:\n",
    "        counts[key] += 1\n",
    "    else:\n",
    "        counts[key] = 1\n",
    "        \n",
    "def tabulate_read(key,value,dict):\n",
    "    # add value to count for this key, or add it to the dictionary    \n",
    "    if key in dict:\n",
    "        dict[key].append(value)\n",
    "    else:\n",
    "        dict[key] = [value]\n",
    "        \n",
    "def write_dict(dict, outputfile):\n",
    "    # write sequences and counts to a text file\n",
    "    print (outputfile)\n",
    "    file = open(outputfile, 'w+')\n",
    "    for w in sorted(dict, key=dict.get, reverse=True):\n",
    "        file.write('{seq}, {num}\\n'.format(seq=w, num=dict[w]))\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNA parsing\n",
    "def parse_dna(file):\n",
    "    fadapter = \"GGATCC\" #BamHI\n",
    "    radapter = \"CTGCAG\" #PstI\n",
    "\n",
    "    #alignment scoring\n",
    "    match = 0\n",
    "    mismatch = -1\n",
    "    gap_open = -1\n",
    "    gap_extend = -1\n",
    "    score_dist = []\n",
    "\n",
    "    sref_bc = set(ref_bc)\n",
    "    exp_err_dist = []\n",
    "    read_trim_len_dist = []\n",
    "    prom_len_dist = []\n",
    "    bc_len_dist = []\n",
    "    \n",
    "    count = 0\n",
    "    both_adaptercount = 0\n",
    "    \n",
    "    lowq_count = 0\n",
    "    missingadapter_count = 0\n",
    "    frag_count = 0\n",
    "    badbc_count = 0\n",
    "    goodbc_perfectalign_count = 0\n",
    "    goodbc_goodalign_count = 0\n",
    "    goodbc_badalign_count = 0\n",
    "    \n",
    "    lowq = defaultdict(int)\n",
    "    missingadapter = defaultdict(int)\n",
    "    frag = defaultdict(int)\n",
    "    badbc = defaultdict(int)\n",
    "    goodbc_perfectalign = defaultdict(list)\n",
    "    goodbc_goodalign = defaultdict(list)\n",
    "    goodbc_badalign = defaultdict(list)\n",
    "    \n",
    "    goodbc_perfectalign_bccounts = defaultdict(int)\n",
    "    goodbc_goodalign_bccounts = defaultdict(int)\n",
    "    \n",
    "    print(\"Parsing of \" + file + \" started at:\" + str(datetime.now()) + \"\\n\")\n",
    "\n",
    "    handle = gzip.open(file,\"rt\")\n",
    "    for rec in SeqIO.parse(handle, 'fastq'):\n",
    "        count +=1\n",
    "        qscore = rec.letter_annotations[\"phred_quality\"]\n",
    "        read = str(rec.seq)\n",
    "        error = exp_err(qscore)\n",
    "        exp_err_dist.append(error)\n",
    "\n",
    "        if error <3:\n",
    "            \n",
    "            if fadapter in read and radapter in read:\n",
    "                both_adaptercount +=1\n",
    "                               \n",
    "                fpos = read.find(fadapter)\n",
    "                rpos = read.find(radapter)\n",
    "                read_trim = read[fpos+len(fadapter):rpos]\n",
    "                read_trim_len_dist.append(len(read_trim))\n",
    "# modified                   \n",
    "                if 117 >= len(read_trim) >= 113:\n",
    "                    prom = read_trim[:-15]\n",
    "                    prom_len_dist.append(len(prom))\n",
    "                    bc = read_trim[-12:]\n",
    "                    bc_len_dist.append(len(bc))\n",
    "                    \n",
    "# modified                  \n",
    "                    sbc = str(bc)\n",
    "                    if len(bc)==12 and 102>=len(prom)>=98:\n",
    "                        \n",
    "                        if sbc in sref_bc:\n",
    "                            if prom == prom_lib[sbc]:\n",
    "                                goodbc_perfectalign_count += 1\n",
    "                                tabulate(sbc,goodbc_perfectalign_bccounts)\n",
    "                                tabulate_read(sbc,prom,goodbc_perfectalign)\n",
    "                                score_dist.append(0)\n",
    "                            else:\n",
    "                                score = pairwise2.align.globalms(prom,prom_lib[sbc],match,mismatch,gap_open,gap_extend,score_only = True)\n",
    "                                score_dist.append(score)\n",
    "# modified\n",
    "                                if score >= (math.ceil(len(prom)*0.04)*-1):\n",
    "                                    goodbc_goodalign_count +=1\n",
    "                                    tabulate(sbc,goodbc_goodalign_bccounts)\n",
    "                                    tabulate_read(sbc,prom,goodbc_goodalign)\n",
    "                                else:\n",
    "                                    goodbc_badalign_count += 1\n",
    "                                    tabulate_read(sbc,prom,goodbc_badalign)\n",
    "                        else:\n",
    "                            badbc_count +=1\n",
    "                            tabulate(read_trim,badbc)\n",
    "                                    \n",
    "                    else:\n",
    "                        badbc_count +=1\n",
    "                        tabulate(read_trim,badbc)\n",
    "                else:\n",
    "                    frag_count +=1  \n",
    "                    tabulate(read_trim,frag)\n",
    "                    \n",
    "            else:\n",
    "                missingadapter_count += 1\n",
    "                tabulate(read,missingadapter)\n",
    "            \n",
    "        else:\n",
    "            tabulate(read,lowq)\n",
    "            lowq_count += 1\n",
    "            \n",
    "        if count >100000:\n",
    "            break\n",
    "            \n",
    "    combined = {}\n",
    "    combined.update(goodbc_perfectalign_bccounts)\n",
    "    combined.update(goodbc_goodalign_bccounts)\n",
    "        \n",
    "    combined_bccounts = {}\n",
    "    for key in combined:\n",
    "        if key in goodbc_goodalign_bccounts and key in goodbc_perfectalign_bccounts:\n",
    "            combined_bccounts[key] = goodbc_goodalign_bccounts[key] + goodbc_perfectalign_bccounts[key] \n",
    "        elif key in goodbc_goodalign_bccounts:\n",
    "            combined_bccounts[key] = goodbc_goodalign_bccounts[key]\n",
    "        else:\n",
    "            combined_bccounts[key] = goodbc_perfectalign_bccounts[key]\n",
    "            \n",
    "    print(\"total count: \" + str(count))\n",
    "    print(\"\")\n",
    "    print(\"lowq count: \" +str(lowq_count) + \" = \" + \"{0:.2f}\".format(float(lowq_count/count)))\n",
    "    print(\"missing_adapter count: \"+ str(missingadapter_count) + \" = \" + \"{0:.2f}\".format(float(missingadapter_count/count)))\n",
    "    print(\"frag count: \" + str(frag_count) + \" = \" + \"{0:.2f}\".format(float(frag_count/count)))\n",
    "    print(\"badbc count: \" + str(badbc_count) + \" = \" + \"{0:.2f}\".format(float(badbc_count/count)))\n",
    "    print(\"goodbc_badalignment count: \" + str(goodbc_badalign_count) + \" = \" + \"{0:.2f}\".format(float(goodbc_badalign_count/count)))\n",
    "    print(\"goodbc_goodalignment count: \" + str(goodbc_goodalign_count) + \" = \" + \"{0:.2f}\".format(float(goodbc_goodalign_count/count)))\n",
    "    print(\"goodbc_perfectalignment count: \" + str(goodbc_perfectalign_count) + \" = \" + \"{0:.2f}\".format(float(goodbc_perfectalign_count/count)))\n",
    "    print(\"\")\n",
    "\n",
    "    filename = file.split(\"/\")[0] + \"/\" + file.split(\"/\")[-1].split(\".\")[0]\n",
    "    runname = file.split(\"/\")[0]\n",
    "    fname = file.split(\"/\")[-1].split(\".\")[0]\n",
    "    d = pd.DataFrame(list(combined_bccounts.items()), columns = ['Barcode', 'Counts'])\n",
    "    d = d.set_index('Barcode')\n",
    "    d.to_csv(\"05_bc_counts/\" + fname + \".csv\")\n",
    "    d2 = pd.read_csv(\"05_bc_counts/\" + fname + \".csv\")\n",
    "\n",
    "    BC = \"\"\n",
    "    BC_lst = []\n",
    "    for BC_rev in d2['Barcode']:\n",
    "        BC = Seq(BC_rev).reverse_complement()\n",
    "        BC = ''.join(BC)\n",
    "        BC_lst.append(BC)\n",
    "    d2['Barcode'] = BC_lst\n",
    "    d2.to_csv(\"05_bc_counts/\" + fname + \".csv\", index=False)\n",
    "    \n",
    "# modified\n",
    "    #write to files\n",
    "    write_dict(combined_bccounts,\"0_bccounts/\" + fname + \".txt\")\n",
    "    write_dict(lowq,\"1_lowq/\" + fname + \".txt\")\n",
    "    write_dict(missingadapter,\"2_missingadapter/\" + fname + \".txt\")\n",
    "    write_dict(frag,\"3_frag/\" + fname + \".txt\")\n",
    "    write_dict(badbc,\"4_badbc/\" + fname + \".txt\")\n",
    "    write_dict(goodbc_badalign,\"5_goodbc_badalign/\" + fname + \".txt\")\n",
    "    write_dict(goodbc_goodalign,\"6_goodbc_goodalign/\" + fname + \".txt\")\n",
    "    write_dict(goodbc_perfectalign,\"7_goodbc_perfectalign/\" + fname + \".txt\")\n",
    "\n",
    "    write_dict(goodbc_goodalign_bccounts,\"8_goodbc_goodalign_bccounts/\" + fname + \".txt\")\n",
    "    write_dict(goodbc_perfectalign_bccounts,\"9_goodbc_perfectalign_bccounts/\" + fname + \".txt\")\n",
    "    \n",
    "    with open(\"10_log_files/\" + fname + \".txt\",\"w+\") as f:\n",
    "        f.write(\"total count: \" + str(count) + \"\\n\")\n",
    "        f.write(\"\" + \"\\n\")\n",
    "        f.write(\"lowq count: \" +str(lowq_count) + \" = \" + \"{0:.2f}\".format(float(lowq_count/count)) + \"\\n\")\n",
    "        f.write(\"missing_adapter count: \"+ str(missingadapter_count) + \" = \" + \"{0:.2f}\".format(float(missingadapter_count/count)) + \"\\n\")\n",
    "        f.write(\"frag count: \" + str(frag_count) + \" = \" + \"{0:.2f}\".format(float(frag_count/count)) + \"\\n\")\n",
    "        f.write(\"badbc count: \" + str(badbc_count) + \" = \" + \"{0:.2f}\".format(float(badbc_count/count)) + \"\\n\")\n",
    "        f.write(\"goodbc_badalignment count: \" + str(goodbc_badalign_count) + \" = \" + \"{0:.2f}\".format(float(goodbc_badalign_count/count)) + \"\\n\")\n",
    "        f.write(\"goodbc_goodalignment count: \" + str(goodbc_goodalign_count) + \" = \" + \"{0:.2f}\".format(float(goodbc_goodalign_count/count)) + \"\\n\")\n",
    "        f.write(\"goodbc_perfectalignment count: \" + str(goodbc_perfectalign_count) + \" = \" + \"{0:.2f}\".format(float(goodbc_perfectalign_count/count)) + \"\\n\")\n",
    "        \n",
    "    print(\"Parsing of \" + file + \" finished at:\" + str(datetime.now()) + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_rna(file):\n",
    "    fadapter = \"GTGGTATCAACGCAGAGTACAT\"\n",
    "    radapter = \"CTGCAGCGT\"\n",
    "\n",
    "\n",
    "    #alignment scoring\n",
    "    match = 0\n",
    "    mismatch = -1\n",
    "    gap_open = -1\n",
    "    gap_extend = -1\n",
    "    score_dist = []\n",
    "\n",
    "    sref_bc = set(ref_bc)\n",
    "    #sref_bc_last10 = set(ref_bc_last10)\n",
    "    \n",
    "    exp_err_dist = []\n",
    "    read_trim_len_dist = []\n",
    "    prom_len_dist = []\n",
    "    bc_len_dist = []\n",
    "    \n",
    "    count = 0\n",
    "    both_adaptercount = 0\n",
    "    \n",
    "    lowq_count = 0\n",
    "    missingadapter_count = 0\n",
    "    frag_count = 0\n",
    "    badbc_count = 0\n",
    "    goodbc_perfectalign_count = 0\n",
    "    goodbc_goodalign_count = 0\n",
    "    goodbc_badalign_count = 0\n",
    "\n",
    "    adapmismatch = defaultdict(int)\n",
    "    \n",
    "    lowq = defaultdict(int)\n",
    "    missingadapter = defaultdict(int)\n",
    "    frag = defaultdict(int)\n",
    "    badbc = defaultdict(int)\n",
    "    goodbc_perfectalign = defaultdict(list)\n",
    "    goodbc_goodalign = defaultdict(list)\n",
    "    goodbc_badalign = defaultdict(list)\n",
    "    \n",
    "    goodbc_perfectalign_bccounts = defaultdict(int)\n",
    "    goodbc_goodalign_bccounts = defaultdict(int)\n",
    "    \n",
    "    print(\"Parsing of \" + file + \" started at:\" + str(datetime.now()) + \"\\n\")\n",
    "    handle = gzip.open(file,\"rt\")\n",
    "    for rec in SeqIO.parse(handle, 'fastq'):\n",
    "        count +=1\n",
    "        qscore = rec.letter_annotations[\"phred_quality\"]\n",
    "        read = str(rec.seq.reverse_complement())\n",
    "        error = exp_err(qscore)\n",
    "        exp_err_dist.append(error)\n",
    "        if error <3:\n",
    "            \n",
    "            if fadapter in read and radapter in read:\n",
    "                both_adaptercount +=1\n",
    "                               \n",
    "                fpos = read.find(fadapter)\n",
    "                rpos = read.find(radapter)\n",
    "                read_trim = read[fpos+len(fadapter):rpos]\n",
    "                read_trim_len_dist.append(len(read_trim))\n",
    "                #print(read_trim)\n",
    "# modified\n",
    "                if 15 < len(read_trim) <= 115: #figure out this line\n",
    "                    prom = read_trim[4:-15] #trim off first six to get rid of the ATGGG\n",
    "                    prom_len_dist.append(len(prom))\n",
    "                    bc = read_trim[-12:]\n",
    "                    bc_len_dist.append(len(bc))\n",
    "                            \n",
    "                    sbc = str(bc)\n",
    "                    if sbc in sref_bc and len(prom)>0:\n",
    "                        trim_prom = prom_lib[sbc][100-len(prom):]                                    \n",
    "                        score = pairwise2.align.globalms(prom,trim_prom,match,mismatch,gap_open,gap_extend,score_only = True)\n",
    "                        if score == 0:\n",
    "                            goodbc_perfectalign_count += 1\n",
    "                            tabulate(sbc,goodbc_perfectalign_bccounts)\n",
    "                            tabulate_read(sbc,prom,goodbc_perfectalign)\n",
    "                            \n",
    "                        elif score >= (math.ceil(len(prom)*0.04)*-1):\n",
    "                            goodbc_goodalign_count +=1\n",
    "                            tabulate(sbc,goodbc_goodalign_bccounts)\n",
    "                            tabulate_read(sbc,prom,goodbc_goodalign)\n",
    "                            score_dist.append(score)\n",
    "                        else:\n",
    "                            score_dist.append(score)\n",
    "                            goodbc_badalign_count += 1\n",
    "                            tabulate_read(sbc,prom,goodbc_badalign)           \n",
    "                    else:\n",
    "                        badbc_count +=1\n",
    "                        tabulate(read_trim,badbc)\n",
    "                else:\n",
    "                    frag_count +=1  \n",
    "                    tabulate(read_trim,frag)\n",
    "            else:\n",
    "                missingadapter_count += 1\n",
    "                tabulate(read,missingadapter)\n",
    "            \n",
    "        else:\n",
    "            tabulate(read,lowq)\n",
    "            lowq_count += 1\n",
    "            \n",
    "        if count >50000:\n",
    "            break  \n",
    "            \n",
    "    combined = {}\n",
    "    combined.update(goodbc_perfectalign_bccounts)\n",
    "    combined.update(goodbc_goodalign_bccounts)\n",
    "        \n",
    "    combined_bccounts = {}\n",
    "    for key in combined:\n",
    "        if key in goodbc_goodalign_bccounts and key in goodbc_perfectalign_bccounts:\n",
    "            combined_bccounts[key] = goodbc_goodalign_bccounts[key] + goodbc_perfectalign_bccounts[key] \n",
    "        elif key in goodbc_goodalign_bccounts:\n",
    "            combined_bccounts[key] = goodbc_goodalign_bccounts[key]\n",
    "        else:\n",
    "            combined_bccounts[key] = goodbc_perfectalign_bccounts[key]\n",
    "\n",
    "    print(\"total count: \" + str(count))\n",
    "    print(\"\")\n",
    "    print(\"lowq count: \" +str(lowq_count) + \" = \" + \"{0:.2f}\".format(float(lowq_count/count)))\n",
    "    print(\"missing_adapter count: \"+ str(missingadapter_count) + \" = \" + \"{0:.2f}\".format(float(missingadapter_count/count)))\n",
    "    print(\"frag count: \" + str(frag_count) + \" = \" + \"{0:.2f}\".format(float(frag_count/count)))\n",
    "    print(\"badbc count: \" + str(badbc_count) + \" = \" + \"{0:.2f}\".format(float(badbc_count/count)))\n",
    "    print(\"goodbc_badalignment count: \" + str(goodbc_badalign_count) + \" = \" + \"{0:.2f}\".format(float(goodbc_badalign_count/count)))\n",
    "    print(\"goodbc_goodalignment count: \" + str(goodbc_goodalign_count) + \" = \" + \"{0:.2f}\".format(float(goodbc_goodalign_count/count)))\n",
    "    print(\"goodbc_perfectalignment count: \" + str(goodbc_perfectalign_count) + \" = \" + \"{0:.2f}\".format(float(goodbc_perfectalign_count/count)))\n",
    "    print(\"\")\n",
    "\n",
    "    filename = file.split(\"/\")[0] + \"/\" + file.split(\"/\")[-1].split(\".\")[0]\n",
    "    runname = file.split(\"/\")[0]\n",
    "    fname = file.split(\"/\")[-1].split(\".\")[0]\n",
    "    d = pd.DataFrame(list(combined_bccounts.items()), columns = ['Barcode', 'Counts'])\n",
    "    d = d.set_index('Barcode')\n",
    "    d.to_csv(\"05_bc_counts/\" + fname + \".csv\")\n",
    "    d2 = pd.read_csv(\"05_bc_counts/\" + fname + \".csv\")\n",
    "\n",
    "    BC = \"\"\n",
    "    BC_lst = []\n",
    "    for BC_rev in d2['Barcode']:\n",
    "        BC = Seq(BC_rev).reverse_complement()\n",
    "        BC = ''.join(BC)\n",
    "        BC_lst.append(BC)\n",
    "    d2['Barcode'] = BC_lst\n",
    "    d2.to_csv(\"05_bc_counts/\" + fname + \".csv\", index=False)\n",
    "    \n",
    "# modified\n",
    "    #write to files\n",
    "    write_dict(combined_bccounts,\"0_bccounts/\" + fname + \".txt\")\n",
    "    write_dict(lowq,\"1_lowq/\" + fname + \".txt\")\n",
    "    write_dict(missingadapter,\"2_missingadapter/\" + fname + \".txt\")\n",
    "    write_dict(frag,\"3_frag/\" + fname + \".txt\")\n",
    "    write_dict(badbc,\"4_badbc/\" + fname + \".txt\")\n",
    "    write_dict(goodbc_badalign,\"5_goodbc_badalign/\" + fname + \".txt\")\n",
    "    write_dict(goodbc_goodalign,\"6_goodbc_goodalign/\" + fname + \".txt\")\n",
    "    write_dict(goodbc_perfectalign,\"7_goodbc_perfectalign/\" + fname + \".txt\")\n",
    "\n",
    "    write_dict(goodbc_goodalign_bccounts,\"8_goodbc_goodalign_bccounts/\" + fname + \".txt\")\n",
    "    write_dict(goodbc_perfectalign_bccounts,\"9_goodbc_perfectalign_bccounts/\" + fname + \".txt\")\n",
    "    \n",
    "    with open(\"10_log_files/\" + fname + \".txt\",\"w+\") as f:\n",
    "        f.write(\"total count: \" + str(count) + \"\\n\")\n",
    "        f.write(\"\" + \"\\n\")\n",
    "        f.write(\"lowq count: \" +str(lowq_count) + \" = \" + \"{0:.2f}\".format(float(lowq_count/count)) + \"\\n\")\n",
    "        f.write(\"missing_adapter count: \"+ str(missingadapter_count) + \" = \" + \"{0:.2f}\".format(float(missingadapter_count/count)) + \"\\n\")\n",
    "        f.write(\"frag count: \" + str(frag_count) + \" = \" + \"{0:.2f}\".format(float(frag_count/count)) + \"\\n\")\n",
    "        f.write(\"badbc count: \" + str(badbc_count) + \" = \" + \"{0:.2f}\".format(float(badbc_count/count)) + \"\\n\")\n",
    "        f.write(\"goodbc_badalignment count: \" + str(goodbc_badalign_count) + \" = \" + \"{0:.2f}\".format(float(goodbc_badalign_count/count)) + \"\\n\")\n",
    "        f.write(\"goodbc_goodalignment count: \" + str(goodbc_goodalign_count) + \" = \" + \"{0:.2f}\".format(float(goodbc_goodalign_count/count)) + \"\\n\")\n",
    "        f.write(\"goodbc_perfectalignment count: \" + str(goodbc_perfectalign_count) + \" = \" + \"{0:.2f}\".format(float(goodbc_perfectalign_count/count)) + \"\\n\")\n",
    "\n",
    "       \n",
    "    print(\"Parsing of \" + file + \" finished at:\" + str(datetime.now()) + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing of merged/158-DNA-1.fastq.gz started at:2020-05-13 14:40:38.054001\n",
      "\n",
      "total count: 100001\n",
      "\n",
      "lowq count: 237 = 0.00\n",
      "missing_adapter count: 971 = 0.01\n",
      "frag count: 7606 = 0.08\n",
      "badbc count: 3750 = 0.04\n",
      "goodbc_badalignment count: 26 = 0.00\n",
      "goodbc_goodalignment count: 27425 = 0.27\n",
      "goodbc_perfectalignment count: 59986 = 0.60\n",
      "\n",
      "0_bccounts/158-DNA-1.txt\n",
      "1_lowq/158-DNA-1.txt\n",
      "2_missingadapter/158-DNA-1.txt\n",
      "3_frag/158-DNA-1.txt\n",
      "4_badbc/158-DNA-1.txt\n",
      "5_goodbc_badalign/158-DNA-1.txt\n",
      "6_goodbc_goodalign/158-DNA-1.txt\n",
      "7_goodbc_perfectalign/158-DNA-1.txt\n",
      "8_goodbc_goodalign_bccounts/158-DNA-1.txt\n",
      "9_goodbc_perfectalign_bccounts/158-DNA-1.txt\n",
      "Parsing of merged/158-DNA-1.fastq.gz finished at:2020-05-13 14:40:48.043825\n",
      "\n",
      "Parsing of merged/158-RNA-1-1.fastq.gz started at:2020-05-13 14:40:48.056821\n",
      "\n",
      "total count: 50001\n",
      "\n",
      "lowq count: 190 = 0.00\n",
      "missing_adapter count: 5543 = 0.11\n",
      "frag count: 6990 = 0.14\n",
      "badbc count: 2478 = 0.05\n",
      "goodbc_badalignment count: 1863 = 0.04\n",
      "goodbc_goodalignment count: 6274 = 0.13\n",
      "goodbc_perfectalignment count: 26663 = 0.53\n",
      "\n",
      "0_bccounts/158-RNA-1-1.txt\n",
      "1_lowq/158-RNA-1-1.txt\n",
      "2_missingadapter/158-RNA-1-1.txt\n",
      "3_frag/158-RNA-1-1.txt\n",
      "4_badbc/158-RNA-1-1.txt\n",
      "5_goodbc_badalign/158-RNA-1-1.txt\n",
      "6_goodbc_goodalign/158-RNA-1-1.txt\n",
      "7_goodbc_perfectalign/158-RNA-1-1.txt\n",
      "8_goodbc_goodalign_bccounts/158-RNA-1-1.txt\n",
      "9_goodbc_perfectalign_bccounts/158-RNA-1-1.txt\n",
      "Parsing of merged/158-RNA-1-1.fastq.gz finished at:2020-05-13 14:40:52.438428\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file in DNAfilepaths:\n",
    "    parse_dna(file)\n",
    "    \n",
    "for file in RNAfilepaths:\n",
    "    parse_rna(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
